{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds  # TFDS to download MNIST.\n",
    "import tensorflow as tf  # TensorFlow / `tf.data` operations.\n",
    "from flax import nnx  # The Flax NNX API.\n",
    "import flax\n",
    "from functools import partial\n",
    "import jax.numpy as jnp  # JAX NumPy\n",
    "import jax\n",
    "import optax\n",
    "from linearRNN import forward_h\n",
    "from linearRNN import forward\n",
    "from linearRNN import init_lru_parameters\n",
    "from linearRNN import binary_operator_diag\n",
    "from linearRNN import compute_lr_sigma\n",
    "from linearRNN import LRU\n",
    "import numpy as np\n",
    "import random\n",
    "from flax import linen as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = 0  # pooling layer after MLP is taking the average over the numbers\n",
    "transformation = 0  # transformation of the data from decimals between 0 and 255 to binary 8 bit numbers\n",
    "leave_data = 1  # download csv data of the results\n",
    "multi_opt = 0  # change the learning rate and the variance of the initialized weights per layer by using the multi-optimizer\n",
    "hidden_neuron = 64  # no details in the 2023 paper => 2024 paper fixed to 512\n",
    "encoded_size = 256\n",
    "hidden_size = 128\n",
    "learning_rate = 0.004\n",
    "momentum = 0.9\n",
    "train_steps = 3000\n",
    "eval_every = 50\n",
    "batch_size = 50\n",
    "r_min = 0.9\n",
    "r_max = 0.999\n",
    "max_phase = 6.28\n",
    "depth = 1\n",
    "lr_factor=0.25\n",
    "method_name = \"LRUMLP\"\n",
    "dataset_name = \"MNIST\"\n",
    "rngs1=nnx.Rngs(random.randint(0,10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_bin_array(arr, m):\n",
    "    # https://stackoverflow.com/questions/22227595/convert-integer-to-binary-array-with-suitable-padding\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    arr: Numpy array of positive integers\n",
    "    m: Number of bits of each integer to retain\n",
    "\n",
    "    Returns a copy of arr with every element replaced with a bit vector.\n",
    "    Bits encoded as int8's.\n",
    "    \"\"\"\n",
    "    to_str_func = np.vectorize(lambda x: np.binary_repr(x).zfill(m))\n",
    "    strs = to_str_func(arr)\n",
    "    ret = np.zeros(list(arr.shape) + [m], dtype=np.int8)\n",
    "    for bit_ix in range(0, m):\n",
    "        fetch_bit_func = np.vectorize(lambda x: x[bit_ix] == \"1\")\n",
    "        ret[..., bit_ix] = fetch_bit_func(strs).astype(\"int8\")\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784, 1)\n",
      "(60000,)\n",
      "(10000, 784, 1)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "\n",
    "if dataset_name == \"MNIST\":\n",
    "    dataset = tf.keras.datasets.mnist.load_data()\n",
    "    train = dataset[0]\n",
    "    test = dataset[1]\n",
    "\n",
    "    train_x_seq = train[0].shape[0]\n",
    "    train_x_len = int(jnp.prod(jnp.array(train[0].shape[1:])))\n",
    "    train_x_size = 1\n",
    "    test_x_seq = test[0].shape[0]\n",
    "    test_x_len = int(jnp.prod(jnp.array(test[0].shape[1:])))\n",
    "    test_x_size = 1\n",
    "    if transformation:  # transform the information of the pixel to 8-bit binary numbers\n",
    "        train_x = train[0].reshape((train_x_seq, train_x_len, train_x_size))\n",
    "        train_x = vec_bin_array(train_x, 8)\n",
    "        train_y = train[1].reshape(train_x_seq)\n",
    "        train_y_class = len(jnp.unique(train_y))\n",
    "        test_x = test[0].reshape((test_x_seq, test_x_len, test_x_size))\n",
    "        test_x = vec_bin_array(test_x, 8)\n",
    "        test_y = test[1].reshape(test_x_seq)\n",
    "    else:\n",
    "        train_x = train[0].reshape((train_x_seq, train_x_len, train_x_size)) / 255\n",
    "        train_y = train[1].reshape(train_x_seq)\n",
    "        train_y_class = len(jnp.unique(train_y))\n",
    "        test_x = test[0].reshape((test_x_seq, test_x_len, test_x_size)) / 255\n",
    "        test_y = test[1].reshape(test_x_seq)\n",
    "\n",
    "if dataset_name == \"CIFAR10\":\n",
    "    dataset = tf.keras.datasets.cifar10.load_data()\n",
    "    train = dataset[0]\n",
    "    test = dataset[1]\n",
    "\n",
    "    train_x_seq = train[0].shape[0]\n",
    "    train_x_len = int(jnp.prod(jnp.array(train[0].shape[1:-1])))\n",
    "    train_x_size = int(jnp.prod(jnp.array(train[0].shape[-1])))\n",
    "\n",
    "    test_x_seq = test[0].shape[0]\n",
    "    test_x_len = int(jnp.prod(jnp.array(test[0].shape[1:-1])))\n",
    "    test_x_size = int(jnp.prod(jnp.array(train[0].shape[-1])))\n",
    "\n",
    "    if (\n",
    "        transformation\n",
    "    ):  # transform the information of the pixel to 3*8-bit binary numbers\n",
    "        train_x = train[0].reshape((train_x_seq, train_x_len, train_x_size))\n",
    "        train_x = vec_bin_array(train_x, 8)\n",
    "        train_y = train[1].reshape(train_x_seq)\n",
    "        train_y_class = len(jnp.unique(train_y))\n",
    "        test_x = test[0].reshape((test_x_seq, test_x_len, test_x_size))\n",
    "        test_x = vec_bin_array(test_x, 8)\n",
    "        test_y = test[1].reshape(test_x_seq)\n",
    "    else:\n",
    "        train_x = train[0].reshape((train_x_seq, train_x_len, train_x_size)) / 255\n",
    "        train_y = train[1].reshape(train_x_seq)\n",
    "        train_y_class = len(jnp.unique(train_y))\n",
    "        test_x = test[0].reshape((test_x_seq, test_x_len, test_x_size)) / 255\n",
    "        test_y = test[1].reshape(test_x_seq)\n",
    "\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (jnp.real(train_x), jnp.array(train_y, dtype=int))\n",
    ")\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (jnp.real(test_x), jnp.array(test_y, dtype=int))\n",
    ")\n",
    "\n",
    "train_ds = train_ds.repeat().shuffle(100)\n",
    "# Group into batches of `batch_size` and skip incomplete batches, prefetch the next sample to improve latency.\n",
    "train_ds = train_ds.batch(batch_size, drop_remainder=True).take(train_steps).prefetch(1)\n",
    "# Group into batches of `batch_size` and skip incomplete batches, prefetch the next sample to improve latency.\n",
    "test_ds = test_ds.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nnx.Module):\n",
    "    # DON'T FORGET TO CHANGE THE MODEL NAME BEFORE RUNNING\n",
    "    # According to the scheme of the paper (Figure 1), input_size=M, encoded_size=H,layer_dim=number of neurons in MLP, out_dim=number of classes\n",
    "    def __init__(\n",
    "        self,\n",
    "        token_size,\n",
    "        token_len,\n",
    "        encoded_dim,\n",
    "        hidden_dim,\n",
    "        layer_dim,\n",
    "        out_dim,\n",
    "        rngs: nnx.Rngs,\n",
    "    ):\n",
    "\n",
    "        # linear encoder\n",
    "        # lrE,sigmaE=compute_lr_sigma(\"input\",token_size,encoded_dim,0,1)\n",
    "        # self.lin_encoder = nnx.Linear(in_features=token_size, out_features=encoded_dim,rngs=rngs,kernel_init=sigmaE*jax.random.normal)\n",
    "        self.lin_encoder = nnx.Linear(\n",
    "            in_features=token_size, out_features=encoded_dim, rngs=rngs\n",
    "        )\n",
    "\n",
    "        # LRU+MLP block\n",
    "        # lrL1, sigmaL1= compute_lr_sigma(\"input\",encoded_dim,layer_dim,0,1)\n",
    "        # lrL2, sigmaL2=compute_lr_sigma(\"output\",0,layer_dim,encoded_dim,1)\n",
    "        # self.linear1 = nnx.Linear(in_features=encoded_dim, out_features=layer_dim, rngs=rngs,kernel_init=sigmaL1*jax.random.normal))\n",
    "        # self.linear2 = nnx.Linear(in_features=layer_dim//2,out_features=encoded_dim,rngs=rngs,kernel_init=sigmaL2*jax.random.normal))\n",
    "        self.rnn = LRU(\n",
    "            in_features=encoded_dim,\n",
    "            hidden_features=hidden_dim,\n",
    "            r_min=r_min,\n",
    "            r_max=r_max,\n",
    "            max_phase=max_phase,\n",
    "        )\n",
    "        self.linear1 = nnx.Linear(\n",
    "            in_features=encoded_dim, out_features=layer_dim, rngs=rngs\n",
    "        )\n",
    "        self.linear2 = nnx.Linear(\n",
    "            in_features=layer_dim // 2, out_features=encoded_dim, rngs=rngs\n",
    "        )\n",
    "        self.batchnorm = nnx.BatchNorm(\n",
    "            num_features=encoded_dim, rngs=rngs,use_running_average=False\n",
    "        )\n",
    "\n",
    "        # Linear layers\n",
    "        if pool:  # If pooling layer takes the average over the token sequence length\n",
    "            self.linear3 = lambda x: jnp.mean(x, axis=1)\n",
    "        else:  # learn the parameters of the linear transformation\n",
    "            self.linear3 = nnx.Linear(in_features=token_len, out_features=1, rngs=rngs)\n",
    "        self.linear4 = nnx.Linear(\n",
    "            in_features=encoded_dim, out_features=out_dim, rngs=rngs\n",
    "        )\n",
    "        self.out_dim = out_dim\n",
    "        self.token_len = token_len\n",
    "        self.dropout = nnx.Dropout(0.1, rngs=rngs)\n",
    "\n",
    "    @nnx.vmap(in_axes=(None, 0, None))\n",
    "    def block_after_batchnorm(self, x, training):\n",
    "        x = self.rnn(x)\n",
    "        x = self.linear1(x)\n",
    "        x = nnx.glu(x, axis=-1)\n",
    "        x = self.dropout(x,deterministic=not training)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "    @nnx.vmap(in_axes=(None, 0))\n",
    "    def final_linear_projections(self, x):\n",
    "        x = self.linear3(x.T)\n",
    "        x = self.linear4(x.T)\n",
    "        return x.reshape(self.out_dim)\n",
    "\n",
    "    def __call__(self, x, training=True):\n",
    "        x = self.lin_encoder(x)\n",
    "        # x=x@self.lin_encoder\n",
    "        y = x.copy()\n",
    "\n",
    "        # LRU+MLP block\n",
    "        x = self.batchnorm(x)  # batch normalization\n",
    "        x = self.block_after_batchnorm(x, training)\n",
    "        x += y  # Skip connection -> p.21 adding for each block\n",
    "\n",
    "        # x = x.T@self.weight #+ self.bias #project from L*H to H*1\n",
    "        # x = self.weight2@x #+ self.bias2#project from H*1 to out_dim\n",
    "        return self.final_linear_projections(x)\n",
    "    \n",
    "\n",
    "\n",
    "model = MLP(\n",
    "    train_x_size,\n",
    "    train_x_len,\n",
    "    encoded_size,\n",
    "    hidden_size,\n",
    "    hidden_neuron,\n",
    "    train_y_class,\n",
    "    rngs=rngs1,\n",
    ")  # eager initialization\n",
    "\n",
    "#nnx.display(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_tuples_to_nested_dict(params):\n",
    "    nested_dict = {}\n",
    "    for outer_key, inner_key in params:\n",
    "        if outer_key not in nested_dict:\n",
    "            nested_dict[outer_key] = {}\n",
    "        nested_dict[outer_key][inner_key] = inner_key\n",
    "    return nested_dict\n",
    "param = nnx.state(model,nnx.Param).flat_state()\n",
    "gr=group_tuples_to_nested_dict(list(param.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_lr=optax.warmup_cosine_decay_schedule(init_value=1e-7*lr_factor, peak_value=learning_rate*lr_factor, warmup_steps=train_steps//10, decay_steps=train_steps, end_value=1e-7*lr_factor)\n",
    "lin_lr=optax.warmup_cosine_decay_schedule(init_value=1e-7, peak_value=learning_rate, warmup_steps=train_steps//10, decay_steps=train_steps, end_value=1e-7)\n",
    "\n",
    "\n",
    "d={\"B_re\":optax.adamw(rnn_lr),\n",
    "   \"B_im\":optax.adamw(rnn_lr),\n",
    "    'C_im': optax.adamw(rnn_lr,weight_decay=0.05), \n",
    "    'C_re': optax.adamw(rnn_lr,weight_decay=0.05),\n",
    "    'D': optax.adamw(rnn_lr,weight_decay=0.05),\n",
    "    'gamma_log': optax.adamw(rnn_lr),\n",
    "    'nu_log': optax.adamw(rnn_lr),\n",
    "    'theta_log': optax.adamw(rnn_lr),\n",
    "     \"kernel\": optax.adamw(lin_lr,weight_decay=0.05),\n",
    "     \"bias\": optax.adamw(lin_lr,weight_decay=0.05),\n",
    "     \"scale\": optax.adamw(lin_lr,weight_decay=0.05),\n",
    "     }\n",
    "#d={\"rnn\":optax.adamw(rnn_lr,weight_decay=0.05),\n",
    "#     \"lin_encoder\": optax.adamw(lin_lr,weight_decay=0.05),\n",
    "#     \"linear1\": optax.adamw(lin_lr,weight_decay=0.05),\n",
    "#     \"linear2\": optax.adamw(lin_lr,weight_decay=0.05),\n",
    "#     \"linear3\": optax.adamw(lin_lr,weight_decay=0.05),\n",
    "#     \"linear4\": optax.adamw(lin_lr,weight_decay=0.05),\n",
    "#     \"batchnorm\":optax.adamw(lin_lr,weight_decay=0.05)\n",
    "#     }\n",
    "tx=optax.multi_transform(d,nnx.State(gr))\n",
    "\n",
    "optimizer = nnx.Optimizer(model, tx)\n",
    "metrics = nnx.MultiMetric(\n",
    "    accuracy=nnx.metrics.Accuracy(),\n",
    "    loss=nnx.metrics.Average(\"loss\"),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.39568603e-01  4.57865834e-01  3.56602281e-01 -5.79375148e-01\n",
      "  -1.35620445e-01  3.65730226e-02 -1.31378114e-01 -7.77419657e-02\n",
      "  -4.17657018e-01 -1.22361787e-01]\n",
      " [-1.04801714e+00 -9.52208877e-01 -2.04841912e-01  7.10328639e-01\n",
      "   6.42444938e-02 -9.67491046e-02  6.93488419e-01 -3.50312501e-01\n",
      "   3.93611819e-01 -9.88364667e-02]\n",
      " [-1.80238008e-01 -1.30119309e-01  1.11062616e-01  4.87084351e-02\n",
      "  -1.74654089e-02 -1.39919873e-02  1.79535508e-01 -1.35954440e-01\n",
      "  -6.85419887e-02 -9.14155021e-02]\n",
      " [ 5.47369123e-01  4.87209618e-01  1.25871420e-01 -4.54960346e-01\n",
      "  -1.12044841e-01  3.53700593e-02 -2.67188340e-01  6.74309060e-02\n",
      "  -2.12499365e-01 -1.28654819e-02]\n",
      " [ 7.71205068e-01  5.52762032e-01  3.22820425e-01 -9.89029467e-01\n",
      "  -2.43469194e-01  1.28164038e-01 -2.16801152e-01 -1.71232939e-01\n",
      "  -6.18409753e-01 -2.22648889e-01]\n",
      " [-1.14002216e+00 -7.85239935e-01 -3.36229742e-01  9.85219598e-01\n",
      "   1.77485391e-01 -1.22668281e-01  4.86679971e-01  3.67675722e-03\n",
      "   6.49396598e-01  1.93326324e-01]\n",
      " [ 1.66899312e+00  1.35917854e+00  5.90245426e-01 -1.37578464e+00\n",
      "  -3.40849340e-01  1.95730299e-01 -7.29169726e-01  1.74227446e-01\n",
      "  -9.94591296e-01 -1.92369282e-01]\n",
      " [-3.52077931e-01 -1.77668005e-01 -7.97256827e-02  3.05580616e-01\n",
      "   8.21395069e-02 -1.51787698e-02  6.77087829e-02 -5.14428690e-03\n",
      "   2.48411134e-01  9.00071636e-02]\n",
      " [ 9.82296348e-01  8.56146455e-01  4.44986194e-01 -9.88777995e-01\n",
      "  -1.96618602e-01  1.26221970e-01 -2.81803906e-01 -9.83505249e-02\n",
      "  -7.05341697e-01 -2.03821555e-01]\n",
      " [-2.20578909e-02  9.17352960e-02 -5.81961721e-02  1.67749494e-01\n",
      "   1.17446370e-02 -1.66432355e-02 -1.69431299e-01  2.36015588e-01\n",
      "   1.69298097e-01  1.25284687e-01]\n",
      " [-1.22533035e+00 -9.66473579e-01 -5.78942776e-01  1.24900794e+00\n",
      "   2.28235960e-01 -2.05212742e-01  3.52621049e-01  9.75255221e-02\n",
      "   9.85282063e-01  2.98060268e-01]\n",
      " [ 9.31719244e-01  8.18767786e-01  4.39718664e-01 -8.75152230e-01\n",
      "  -2.17946112e-01  1.70633763e-01 -3.25017542e-01  1.36192068e-02\n",
      "  -7.35970140e-01 -2.41011545e-01]\n",
      " [-3.15616220e-01 -1.71557888e-01 -1.29350275e-01  2.63369828e-01\n",
      "  -2.35347562e-02 -2.09303610e-02  1.60690486e-01 -3.55780125e-04\n",
      "   1.17750317e-01  2.73320451e-02]\n",
      " [-1.49149668e+00 -1.21994662e+00 -5.79284012e-01  1.33174288e+00\n",
      "   2.60457069e-01 -2.21048802e-01  4.82394487e-01  1.54167265e-02\n",
      "   9.98242855e-01  3.43893677e-01]\n",
      " [ 1.66284561e+00  1.42123699e+00  7.32100368e-01 -1.77459145e+00\n",
      "  -3.49065840e-01  2.66334116e-01 -5.36945045e-01 -1.72382087e-01\n",
      "  -1.18411779e+00 -3.60379815e-01]\n",
      " [-3.65685314e-01 -2.84240007e-01 -1.30177438e-01  4.34394091e-01\n",
      "   2.43028067e-02 -6.12030923e-02  1.50143370e-01  3.44203524e-02\n",
      "   1.90381706e-01  2.37664897e-02]\n",
      " [-2.93345898e-01 -2.03860149e-01 -7.66981095e-02  2.42942452e-01\n",
      "   3.36479321e-02 -5.10440804e-02  8.82680565e-02 -2.17403919e-02\n",
      "   1.58021480e-01  3.07742432e-02]\n",
      " [ 1.31571755e-01  1.43123999e-01  7.23001063e-02 -1.50534451e-01\n",
      "  -7.33945891e-02  1.01487152e-03 -6.14753142e-02 -2.17367485e-02\n",
      "  -5.07502742e-02 -9.33781173e-03]\n",
      " [ 4.59121674e-01  4.59264636e-01  1.29178628e-01 -3.04403722e-01\n",
      "  -1.01469994e-01  4.69553024e-02 -3.04910839e-01  1.40640020e-01\n",
      "  -1.52637929e-01  1.50333568e-02]\n",
      " [ 2.83650279e+00  2.35513210e+00  1.09145725e+00 -2.44137955e+00\n",
      "  -5.10699987e-01  3.79073411e-01 -1.12735450e+00  2.37271965e-01\n",
      "  -1.81740403e+00 -4.46480632e-01]\n",
      " [-8.95499408e-01 -6.72101557e-01 -3.28579187e-01  5.89236856e-01\n",
      "   6.10375181e-02 -1.04593799e-01  4.02620912e-01 -1.97115585e-01\n",
      "   5.25987267e-01  9.42071229e-02]\n",
      " [ 2.08493376e+00  1.68681622e+00  8.67321014e-01 -1.89817786e+00\n",
      "  -3.87535632e-01  2.83038646e-01 -7.67032504e-01  4.15539443e-02\n",
      "  -1.35669887e+00 -3.55870038e-01]\n",
      " [ 5.95105290e-01  3.91405553e-01  2.17262536e-01 -7.58924842e-01\n",
      "  -1.88236624e-01  8.79743546e-02 -1.02137238e-01 -1.36055857e-01\n",
      "  -5.17666519e-01 -1.77134782e-01]\n",
      " [ 1.19765675e+00  9.45831060e-01  4.58829641e-01 -1.20811009e+00\n",
      "  -2.98097074e-01  1.60040706e-01 -3.99614096e-01 -2.30463222e-02\n",
      "  -8.97902489e-01 -3.02385628e-01]\n",
      " [ 1.22690666e+00  1.02707338e+00  4.39339519e-01 -9.39853430e-01\n",
      "  -2.57288337e-01  1.20918229e-01 -5.89617491e-01  1.57827020e-01\n",
      "  -6.03065133e-01 -8.57080221e-02]\n",
      " [-1.26634002e-01  1.10104308e-03  5.05990386e-02  7.53718615e-02\n",
      "  -6.10370375e-02  3.42171127e-03  1.46463320e-01 -1.34232253e-01\n",
      "   3.23185325e-03 -7.95781538e-02]\n",
      " [ 1.35265470e+00  1.09180880e+00  7.05449820e-01 -1.23465204e+00\n",
      "  -3.03154320e-01  1.92688555e-01 -3.93645078e-01 -6.72522932e-02\n",
      "  -1.08704042e+00 -3.41586292e-01]\n",
      " [-2.09302664e+00 -1.60552013e+00 -7.53968656e-01  1.93895817e+00\n",
      "   4.20007259e-01 -2.96724349e-01  7.41792560e-01 -1.00083649e-02\n",
      "   1.45362926e+00  4.33417559e-01]\n",
      " [ 5.01646280e-01  5.09139061e-01  1.84856623e-01 -2.31927544e-01\n",
      "  -1.26948327e-01  4.80154045e-02 -2.86854684e-01  1.99501872e-01\n",
      "  -2.23288924e-01  5.97553514e-03]\n",
      " [-1.71551272e-01 -1.79923296e-01 -5.98706678e-02  7.50358403e-02\n",
      "   5.90569861e-02 -5.09392209e-02  5.68725429e-02  1.74702145e-03\n",
      "   4.53059897e-02  7.92521331e-03]\n",
      " [ 8.89590383e-01  7.37298846e-01  3.03150445e-01 -6.88050628e-01\n",
      "  -1.48800060e-01  8.30781907e-02 -4.15607274e-01  1.02372289e-01\n",
      "  -4.67534840e-01 -8.61765444e-02]\n",
      " [-2.93767452e-01 -2.21518844e-01 -1.45018846e-01  1.79171741e-01\n",
      "   1.51646510e-02 -1.60685144e-02  5.91540821e-02 -1.10737281e-02\n",
      "   2.34103411e-01  8.94658417e-02]\n",
      " [-1.25541127e+00 -1.08394456e+00 -3.96134615e-01  8.87832999e-01\n",
      "   2.07322776e-01 -1.50116667e-01  5.63667238e-01 -2.20628679e-01\n",
      "   6.76367283e-01  1.12216756e-01]\n",
      " [ 8.12528014e-01  7.09922969e-01  3.65134150e-01 -5.31043768e-01\n",
      "  -1.31130204e-01  4.64076102e-02 -3.81642193e-01  1.98535815e-01\n",
      "  -4.55529630e-01 -7.30028898e-02]\n",
      " [ 3.14732027e+00  2.55145025e+00  9.98556852e-01 -2.63256907e+00\n",
      "  -5.66148996e-01  3.99855047e-01 -1.42117119e+00  3.54886413e-01\n",
      "  -1.87265730e+00 -3.58373135e-01]\n",
      " [-4.08382982e-01 -3.32276106e-01 -1.93948299e-01  2.23852366e-01\n",
      "   4.11295705e-02 -5.31295799e-02  1.44317433e-01 -7.33879283e-02\n",
      "   2.54156440e-01  8.82846043e-02]\n",
      " [ 1.93283308e+00  1.68550634e+00  8.78336728e-01 -1.76579046e+00\n",
      "  -3.30755204e-01  3.45372856e-01 -7.31012940e-01  6.95913285e-02\n",
      "  -1.36117721e+00 -3.07590783e-01]\n",
      " [ 6.75166622e-02  1.10987075e-01 -3.72982374e-03  7.97050446e-02\n",
      "   5.99320140e-03 -2.57026162e-02 -1.97886303e-01  2.08083630e-01\n",
      "   1.30292147e-01  8.25927630e-02]\n",
      " [ 1.54558814e+00  1.27274108e+00  4.34381723e-01 -1.34598637e+00\n",
      "  -3.21285665e-01  2.24571928e-01 -6.96633637e-01  1.37505651e-01\n",
      "  -8.93859386e-01 -2.21261978e-01]\n",
      " [ 1.12625456e+00  8.87571037e-01  3.08869481e-01 -7.39242435e-01\n",
      "  -1.81201026e-01  6.27695471e-02 -5.59918344e-01  2.69540936e-01\n",
      "  -4.98202145e-01 -7.26263523e-02]\n",
      " [ 2.46173263e-01  3.82025182e-01  2.57310003e-01 -2.08592325e-01\n",
      "  -5.38779274e-02  4.60353941e-02 -1.82511091e-01  7.17206374e-02\n",
      "  -1.71540976e-01 -2.89954543e-02]\n",
      " [ 2.39230061e+00  1.97954130e+00  8.91867757e-01 -1.95218372e+00\n",
      "  -3.97989303e-01  2.67640561e-01 -1.06836581e+00  2.73790359e-01\n",
      "  -1.42410564e+00 -2.30716407e-01]\n",
      " [ 2.35173821e+00  1.98078227e+00  9.74254131e-01 -1.92986441e+00\n",
      "  -4.65405256e-01  2.67159015e-01 -9.03208852e-01  2.31479451e-01\n",
      "  -1.54786396e+00 -3.91465783e-01]\n",
      " [ 1.74087238e+00  1.46220863e+00  7.98284888e-01 -1.58551109e+00\n",
      "  -3.47997457e-01  2.60812134e-01 -5.98192692e-01  1.48165822e-02\n",
      "  -1.21514535e+00 -3.54100674e-01]\n",
      " [ 2.40313148e+00  1.97922575e+00  1.07538676e+00 -2.28459978e+00\n",
      "  -4.17568445e-01  3.63612175e-01 -8.70681643e-01  1.37130320e-02\n",
      "  -1.67247653e+00 -4.36953306e-01]\n",
      " [ 1.00681949e+00  7.92854548e-01  4.73145574e-01 -9.15742755e-01\n",
      "  -2.14676514e-01  1.11751541e-01 -3.12083781e-01 -6.24393672e-03\n",
      "  -7.22048879e-01 -2.28565678e-01]\n",
      " [-4.52569015e-02  6.74511641e-02 -2.39048488e-02  1.07210606e-01\n",
      "   9.67797823e-03  4.75942343e-03 -6.93520531e-02  7.67058805e-02\n",
      "   1.60542518e-01  1.53378442e-01]\n",
      " [-1.71736503e+00 -1.38824618e+00 -6.15707040e-01  1.17920780e+00\n",
      "   2.15027198e-01 -1.38431743e-01  8.60519707e-01 -2.69150108e-01\n",
      "   8.22347701e-01  9.40227956e-02]\n",
      " [ 2.63870382e+00  2.19934869e+00  1.11020970e+00 -2.36904287e+00\n",
      "  -5.73904634e-01  3.67455661e-01 -9.83066380e-01  3.88555825e-02\n",
      "  -1.78917480e+00 -4.84589368e-01]\n",
      " [ 1.23813629e-01  1.46995127e-01  6.09451905e-02 -1.90535352e-01\n",
      "  -1.09495178e-01  5.24296276e-02  7.16876239e-05 -8.92462954e-03\n",
      "  -2.04222888e-01 -3.32771838e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Test the model with the first batch\n",
    "for step, batch in enumerate(train_ds.as_numpy_iterator()):\n",
    "    batch1 = batch\n",
    "    break\n",
    "a = model(batch1[0],training=False)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "def loss_fn(model: MLP, batch,training):\n",
    "  logits = model(batch[0],training=training)\n",
    "  loss = optax.softmax_cross_entropy_with_integer_labels(\n",
    "    logits=logits, labels=batch[1]\n",
    "  ).mean()\n",
    "  #print(logits.shape)\n",
    "  #print(batch[1].shape)\n",
    "  return loss, logits\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model: MLP, optimizer: nnx.Optimizer, metrics: nnx.MultiMetric, batch):\n",
    "  \"\"\"Train for a single step.\"\"\"\n",
    "  grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n",
    "  (loss, logits), grads = grad_fn(model, batch,True)\n",
    "  metrics.update(loss=loss, logits=logits, labels=batch[1])  # In-place updates.\n",
    "  optimizer.update(grads)  # In-place updates.\n",
    "  #predicted_labels = jnp.argmax(logits, axis=-1)\n",
    "  #actual_labels = batch[1]\n",
    "  #jax.debug.print(\"Predictions: {}\",predicted_labels[:5].astype(int))\n",
    "  #jax.debug.print(\"Actual Labels: {}\",actual_labels[:5].astype(int))\n",
    "\n",
    "@nnx.jit\n",
    "def eval_step(model: MLP, metrics: nnx.MultiMetric, batch):\n",
    "  loss, logits = loss_fn(model, batch,False)\n",
    "  metrics.update(loss=loss, logits=logits, labels=batch[1])  # In-place updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seori\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\jax\\_src\\lax\\lax.py:3373: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  x_bar = _convert_element_type(x_bar, x.aval.dtype, x.aval.weak_type)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 14\u001b[0m\n\u001b[0;32m      2\u001b[0m metrics_history \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[0;32m      7\u001b[0m }\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_ds\u001b[38;5;241m.\u001b[39mas_numpy_iterator()):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Run the optimization for one step and make a stateful update to the following:\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# - The train state's model parameters\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# - The optimizer state\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# - The training loss and accuracy batch metrics\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m         step \u001b[38;5;241m%\u001b[39m eval_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m step \u001b[38;5;241m==\u001b[39m train_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     18\u001b[0m     ):  \u001b[38;5;66;03m# One training epoch has passed.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;66;03m# Log the training metrics.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m metric, value \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mcompute()\u001b[38;5;241m.\u001b[39mitems():  \u001b[38;5;66;03m# Compute the metrics.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\seori\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flax\\nnx\\graph.py:1041\u001b[0m, in \u001b[0;36mUpdateContextManager.__call__.<locals>.update_context_manager_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_context_manager_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1040\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m-> 1041\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\seori\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\flax\\nnx\\transforms\\compilation.py:345\u001b[0m, in \u001b[0;36mjit.<locals>.jit_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fun)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;129m@graph\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_context(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjit_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    338\u001b[0m   pure_args, pure_kwargs \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mto_tree(\n\u001b[0;32m    339\u001b[0m     (args, kwargs),\n\u001b[0;32m    340\u001b[0m     prefix\u001b[38;5;241m=\u001b[39m(in_shardings, kwarg_shardings),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    343\u001b[0m     ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    344\u001b[0m   )\n\u001b[1;32m--> 345\u001b[0m   pure_args_out, pure_kwargs_out, pure_out \u001b[38;5;241m=\u001b[39m \u001b[43mjitted_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpure_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpure_kwargs\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m   _args_out, _kwargs_out, out \u001b[38;5;241m=\u001b[39m extract\u001b[38;5;241m.\u001b[39mfrom_tree(\n\u001b[0;32m    349\u001b[0m     (pure_args_out, pure_kwargs_out, pure_out), ctxtag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjit\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    350\u001b[0m   )\n\u001b[0;32m    351\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\seori\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\jax\\_src\\tree_util.py:1084\u001b[0m, in \u001b[0;36mregister_static.<locals>.<lambda>\u001b[1;34m(obj, empty_iter_children)\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Registers `cls` as a pytree with no leaves.\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \n\u001b[0;32m   1055\u001b[0m \u001b[38;5;124;03mInstances are treated as static by :func:`jax.jit`, :func:`jax.pmap`, etc. This can\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;124;03m  Array(3, dtype=int32, weak_type=True)\u001b[39;00m\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m flatten \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m obj: ((), obj)\n\u001b[1;32m-> 1084\u001b[0m unflatten \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m obj, empty_iter_children: obj\n\u001b[0;32m   1085\u001b[0m register_pytree_with_keys(\u001b[38;5;28mcls\u001b[39m, flatten, unflatten)\n\u001b[0;32m   1086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model + evaluation with the test data\n",
    "metrics_history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_accuracy\": [],\n",
    "    \"test_loss\": [],\n",
    "    \"test_accuracy\": [],\n",
    "}\n",
    "\n",
    "for step, batch in enumerate(train_ds.as_numpy_iterator()):\n",
    "    # Run the optimization for one step and make a stateful update to the following:\n",
    "    # - The train state's model parameters\n",
    "    # - The optimizer state\n",
    "    # - The training loss and accuracy batch metrics\n",
    "    train_step(model, optimizer, metrics, batch)\n",
    "\n",
    "    if step > 0 and (\n",
    "        step % eval_every == 0 or step == train_steps - 1\n",
    "    ):  # One training epoch has passed.\n",
    "        # Log the training metrics.\n",
    "        for metric, value in metrics.compute().items():  # Compute the metrics.\n",
    "            metrics_history[f\"train_{metric}\"].append(value)  # Record the metrics.\n",
    "        metrics.reset()  # Reset the metrics for the test set.\n",
    "\n",
    "        # Compute the metrics on the test set after each training epoch.\n",
    "        for test_batch in test_ds.as_numpy_iterator():\n",
    "            eval_step(model, metrics, test_batch)\n",
    "\n",
    "        # Log the test metrics.\n",
    "        for metric, value in metrics.compute().items():\n",
    "            metrics_history[f\"test_{metric}\"].append(value)\n",
    "        metrics.reset()  # Reset the metrics for the next training epoch.\n",
    "\n",
    "        print(\n",
    "            f\"[train] step: {step}, \"\n",
    "            f\"loss: {metrics_history['train_loss'][-1]}, \"\n",
    "            f\"accuracy: {metrics_history['train_accuracy'][-1] * 100}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"[test] step: {step}, \"\n",
    "            f\"loss: {metrics_history['test_loss'][-1]}, \"\n",
    "            f\"accuracy: {metrics_history['test_accuracy'][-1] * 100}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training results into csv file\n",
    "import pandas as pd\n",
    "\n",
    "if leave_data:\n",
    "    data = pd.DataFrame(\n",
    "        {\n",
    "            \"step\": np.arange(eval_every, train_steps + eval_every, eval_every),\n",
    "            \"train_loss\": metrics_history[\"train_loss\"],\n",
    "            \"test_loss\": metrics_history[\"test_loss\"],\n",
    "            \"train_accuracy\": metrics_history[\"train_accuracy\"],\n",
    "            \"test_accuracy\": metrics_history[\"test_accuracy\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    data.to_csv(\n",
    "        method_name\n",
    "        + \"_enc\"\n",
    "        + str(encoded_size)\n",
    "        + \"_nr\"\n",
    "        + str(hidden_neuron)\n",
    "        + \"_d\"\n",
    "        + str(hidden_size)\n",
    "        + \"_lr\"\n",
    "        + str(learning_rate)\n",
    "        +\"_\"\n",
    "        + dataset_name\n",
    "        + \"_step\"\n",
    "        + str(train_steps)\n",
    "        + \"r_min_\"\n",
    "        + str(r_min)\n",
    "        + \"r_max\"\n",
    "        + str(r_max)\n",
    "        + \".csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(\n",
    "    np.arange(eval_every, train_steps + eval_every, eval_every),\n",
    "    metrics_history[\"train_loss\"],\n",
    "    label=\"train loss\",\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(eval_every, train_steps + eval_every, eval_every),\n",
    "    metrics_history[\"test_loss\"],\n",
    "    label=\"test loss\",\n",
    ")\n",
    "plt.title(\n",
    "    \"Train loss of \"\n",
    "    + dataset_name\n",
    "    + \" dataset with \"\n",
    "    + method_name\n",
    "    + \", \\nhidden dimension=\"\n",
    "    + str(hidden_size)\n",
    "    + \", number of neuron=\"\n",
    "    + str(hidden_neuron)\n",
    ")\n",
    "plt.xlabel(\"Training step\")\n",
    "plt.ylabel(\"Train loss (cross entropy)\")\n",
    "plt.legend()\n",
    "if leave_data:\n",
    "    plt.savefig(\n",
    "        \"loss_\"\n",
    "        + method_name\n",
    "        + \"_\"\n",
    "        + str(encoded_size)\n",
    "        + \"_\"\n",
    "        + str(hidden_neuron)\n",
    "        + \"_\"\n",
    "        + dataset_name\n",
    "        + \"_step\"\n",
    "        + str(train_steps)\n",
    "        + \"r_min_\"\n",
    "        + str(r_min)\n",
    "        + \"r_max\"\n",
    "        + str(r_max)\n",
    "        + \".jpg\"\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy\n",
    "plt.plot(\n",
    "    np.arange(eval_every, train_steps + eval_every, eval_every),\n",
    "    metrics_history[\"train_accuracy\"],\n",
    "    label=\"train\",\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(eval_every, train_steps + eval_every, eval_every),\n",
    "    metrics_history[\"test_accuracy\"],\n",
    "    label=\"test\",\n",
    ")\n",
    "plt.title(\n",
    "    \"Accuracy of \"\n",
    "    + dataset_name\n",
    "    + \" dataset with \"\n",
    "    + method_name\n",
    "    + \", \\nhidden dimension=\"\n",
    "    + str(hidden_size)\n",
    "    + \", number of neuron=\"\n",
    "    + str(hidden_neuron)\n",
    ")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "if leave_data:\n",
    "    plt.savefig(\n",
    "        \"accuracy_\"\n",
    "        + method_name\n",
    "        + \"_\"\n",
    "        + str(encoded_size)\n",
    "        + \"_\"\n",
    "        + str(hidden_neuron)\n",
    "        + \"_\"\n",
    "        + dataset_name\n",
    "        + \"_step\"\n",
    "        + str(train_steps)\n",
    "        + \"r_min_\"\n",
    "        + str(r_min)\n",
    "        + \"r_max\"\n",
    "        + str(r_max)\n",
    "        + \".jpg\"\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lru",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
